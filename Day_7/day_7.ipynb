{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe7eed45",
   "metadata": {},
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df18663c",
   "metadata": {},
   "source": [
    "Conceptual: Why does a static preference dataset become insufficient as a policy improves? Explain using an example: initial model outputs are poor, so human preferences cover only easy mistakes; once the model stops making those, the old data is less relevant. How does online DPO address this?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cb28f9",
   "metadata": {},
   "source": [
    "## Solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8485ca",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
